{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tables\n",
    "\n",
    "TO PREPARE:\n",
    " - The .csv files referenced below are STRAIGHT exports from the Socrata Files. \n",
    " - Each Socrata file is linked below. \n",
    "\n",
    " - The 311 data .csv import implies that you downloaded a monolithic 311 file from Socrata and then ran bash \"split\" on the file. \n",
    " - Once the split files were obtained, you then further processed them to `cat columns.311 [split_file] > [split_file]_c` to obtain properly \"headered\" split files. \n",
    "\n",
    "TO DO: \n",
    " - Please note that the guess_sql code above makes absurdly large varchar fields to account for large description fields in some data tables (specifically HPD Violations NOVDescription)\n",
    " - Need to clean up the field names for 311\n",
    "\n",
    "NOTES: \n",
    " - Far below is some random SQL SELECT statements\n",
    " - Far below are SQL statements for creating table indices\n",
    " - Questions: jpf321@gmail.com slack: jpfreeley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import desired libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T00:43:32.384817",
     "start_time": "2016-11-21T00:43:30.537394"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will log to /Users/jfreeley/Desktop/HeatSeek/db_import.log\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "BASE_DIR = '/Users/jfreeley/Desktop/HeatSeek/'\n",
    "\n",
    "LOG_FILE = BASE_DIR+'db_import.log'\n",
    "\n",
    "logging.basicConfig(format= '[%(asctime)s] {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    filename=LOG_FILE, \n",
    "    level=logging.INFO)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "print \"This notebook will log to {}\".format(LOG_FILE)\n",
    "log.info(\"This notebook will log to {}\".format(LOG_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-16T13:40:58.696220",
     "start_time": "2016-11-16T13:40:58.691108"
    }
   },
   "source": [
    "# Initialize connection to AWS mySQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T00:43:32.458119",
     "start_time": "2016-11-21T00:43:32.388899"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### AWS\n",
    "engine = create_engine('mysql+mysqlconnector://hsdbuser:156lafayette@hsdb.cjjva3uq32na.us-west-2.rds.amazonaws.com:3306/heatseek', echo=False)\n",
    "\n",
    "### LOCALHOST\n",
    "### INSTALL ON MAC\n",
    "### brew update\n",
    "### brew doctor\n",
    "### brew upgrade\n",
    "### brew install mysql\n",
    "### brew services start mysql\n",
    "\n",
    "#engine = create_engine('mysql+mysqlconnector://root@localhost/heatseek', echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T00:43:34.656444",
     "start_time": "2016-11-21T00:43:34.501392"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_COLUMN_LENGTH = 255\n",
    "\n",
    "\n",
    "def guess_sqlcol(dfparam):    \n",
    "\n",
    "## GUESS AT SQL COLUMN TYPES FROM DataFrame dtypes. \n",
    "    \n",
    "    dtypedict = {}\n",
    "    for i,j in zip(dfparam.columns, dfparam.dtypes):\n",
    "        if \"object\" in str(j):\n",
    "            dtypedict.update({i: sqlalchemy.types.NVARCHAR(length=MAX_COLUMN_LENGTH)}) ##big field length for HPD violations description\n",
    "\n",
    "        if \"datetime\" in str(j):\n",
    "            dtypedict.update({i: sqlalchemy.types.DateTime()})\n",
    "\n",
    "        if \"float\" in str(j):\n",
    "            dtypedict.update({i: sqlalchemy.types.Float(precision=20, asdecimal=True)}) ##big precision for LAT/LONG fields\n",
    "\n",
    "        if \"int\" in str(j):\n",
    "            dtypedict.update({i: sqlalchemy.types.INT()})\n",
    "\n",
    "    return dtypedict\n",
    "\n",
    "\n",
    "def hpd_csv2sql(description, input_csv_file, sep_char, output_pickle,\\\n",
    "            table_name, dtype_dict, load_pickle, \\\n",
    "                input_pickle, db_action, truncate_columns, date_time_columns,\\\n",
    "               chunk_size, keep_cols):\n",
    "\n",
    "    log.info(\"Beginning {} Import {}\".format(description,datetime.datetime.now()))\n",
    "    \n",
    "    if load_pickle == True:\n",
    "        log.info(\"Flagged load of PICKLE: {} = True\".format(input_pickle))\n",
    "        \n",
    "        with open(input_pickle, 'r') as picklefile:\n",
    "            log.info(\"Begin OPEN {} Pickle: {}\".format(input_pickle, datetime.datetime.now()))\n",
    "            log.info(\"Great we have a pickle file...Loading from {}\".format(input_pickle))\n",
    "            df = pickle.load(picklefile)\n",
    "\n",
    "    else: \n",
    "        log.info(\"Reading CSV from {} .. This may take a while...\".format(input_csv_file))\n",
    "        \n",
    "        with open(input_csv_file, 'r') as input_csv: ## should just change to IF EXISTS rather than open()???\n",
    "            df = pd.read_csv(input_csv_file , sep=sep_char, dtype=dtype_dict)\n",
    "                \n",
    "        log.info(\"Why don't we save {} for next time\".format(output_pickle))\n",
    "        \n",
    "        with open(output_pickle, 'w') as picklefile:\n",
    "            log.info(\"Begin {} Pickle: {}\".format(description,datetime.datetime.now()))\n",
    "            pickle.dump(df, picklefile)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## LET'S SEE IF THERE ARE COLUMNS TO TRUNCATE\n",
    "    ## CLEAN COLUMN NAMES\n",
    "    cols = [i.lower().replace(\" \",\"_\").replace(\"'\",\"\").replace(\"\\xe2\\x80\\x99\",\"\").\\\n",
    "            replace(\"#\",\"num\").replace(\"&\",\"and\").replace(\"(\",\"\").\\\n",
    "            replace(\")\",\"\") for i in df.columns]\n",
    "    df.columns = cols\n",
    "    \n",
    "    ## KEEP ONLY THE COLUMNS OF INTEREST\n",
    "    df = df[keep_cols]\n",
    "    \n",
    "    ## TRIM COLUMN DATA TO MAX_LENGTH\n",
    "    for i in truncate_columns:\n",
    "        df[i] = df[i].str[:MAX_COLUMN_LENGTH]\n",
    "    \n",
    "    ## CONVERT DTETIME COLS TO DATETIME\n",
    "    for i in date_time_columns:\n",
    "        df[i] = pd.to_datetime(df[i])\n",
    "\n",
    "        \n",
    "    log.info(\"Let's now try to send it to the DB\")\n",
    "    outputdict = guess_sqlcol(df)  #Guess at SQL columns based on DF dtypes\n",
    "\n",
    "    log.info(\"Begin Upload {} SQL\".format(description, datetime.datetime.now()))\n",
    "    log.info(\"Let's see if we should replace or append our table ... {}\".format(db_action))\n",
    "\n",
    "    if db_action == 'replace': \n",
    "        \n",
    "        action = db_action \n",
    "\n",
    "    else:\n",
    "        \n",
    "        action = 'append'\n",
    "    \n",
    "    log.info(\"We're going with db_action = {}\".format(action))\n",
    "    log.info(\"Sending our df to {}\".format(table_name))\n",
    "    df.to_sql(name=table_name, con=engine, if_exists = action,\\\n",
    "              index=False, chunksize=chunk_size, dtype = outputdict)\n",
    "\n",
    "    log.info(\"Completed {} Import\".format(description, datetime.datetime.now()))\n",
    "    log.info(\"Imported: {} rows\".format(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOB Permits\n",
    "https://data.cityofnewyork.us/Housing-Development/DOB-Permit-Issuance/ipu4-2q9a\n",
    "\n",
    "I have purposefully dropped all Owner/Filer/Superintendant information. If needed in the future, it can be re-added and linked via job_num and job_doc._num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T22:26:55.236226",
     "start_time": "2016-11-20T22:15:58.181840"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perm_dob_dtype_dict = {\n",
    "'borough':                                'object',\n",
    "'bin_num':                               'float64',\n",
    "'house_num':                              'object',\n",
    "'street_name':                            'object',\n",
    "'job_num':                               'float64',\n",
    "'job_doc._num':                          'float64',\n",
    "'job_type':                               'object',\n",
    "'self_cert':                              'object',\n",
    "'block':                                 'float64',\n",
    "'lot':                                    'object',\n",
    "'community_board':                        'object',\n",
    "'zip_code':                               'object',\n",
    "'bldg_type':                             'float64',\n",
    "'residential':                            'object',\n",
    "'special_district_1':                     'object',\n",
    "'special_district_2':                     'object',\n",
    "'work_type':                              'object',\n",
    "'permit_status':                          'object',\n",
    "'filing_status':                          'object',\n",
    "'permit_type':                            'object',\n",
    "'permit_sequence_num':                   'float64',\n",
    "'permit_subtype':                         'object',\n",
    "'oil_gas':                                'object',\n",
    "'site_fill':                              'object',\n",
    "'filing_date':                            'object',\n",
    "'issuance_date':                          'object',\n",
    "'expiration_date':                        'object',\n",
    "'job_start_date':                         'object',\n",
    "'permittees_first_name':                  'object',\n",
    "'permittees_last_name':                   'object',\n",
    "'permittees_business_name':               'object',\n",
    "'permittees_phone_num':                   'object',\n",
    "'permittees_license_type':                'object',\n",
    "'permittees_license_num':                 'object',\n",
    "'act_as_superintendent':                  'object',\n",
    "'permittees_other_title':                 'object',\n",
    "'hic_license':                            'object',\n",
    "'site_safety_mgrs_first_name':            'object',\n",
    "'site_safety_mgrs_last_name':             'object',\n",
    "'site_safety_mgr_business_name':          'object',\n",
    "'superintendent_first_and_last_name':     'object',\n",
    "'superintendent_business_name':           'object',\n",
    "'owners_business_type':                   'object',\n",
    "'non-profit':                             'object',\n",
    "'owners_business_name':                   'object',\n",
    "'owners_first_name':                      'object',\n",
    "'owners_last_name':                       'object',\n",
    "'owners_house_num':                       'object',\n",
    "'owners_house_street_name':               'object',\n",
    "'owners_house_city':                      'object',\n",
    "'owners_house_state':                     'object',\n",
    "'owners_house_zip_code':                  'object',\n",
    "'owners_phone_num':                       'object',\n",
    "'dobrundate':                             'object'}\n",
    "\n",
    "\n",
    "perm_dob_date_time_columns = ['filing_date', 'issuance_date', 'expiration_date', 'job_start_date', 'dobrundate']\n",
    "\n",
    "perm_dob_df_keep_cols = [\n",
    "    'borough',\n",
    "    'bin_num',\n",
    "    'house_num',\n",
    "    'street_name',\n",
    "    'job_num',\n",
    "    'job_doc._num',\n",
    "    'job_type',\n",
    "    'block',\n",
    "    'lot',\n",
    "    'zip_code',\n",
    "    'bldg_type',\n",
    "    'residential',\n",
    "    'work_type',\n",
    "    'permit_status',\n",
    "    'filing_status',\n",
    "    'permit_type',\n",
    "    'filing_date',\n",
    "    'issuance_date',\n",
    "    'expiration_date',\n",
    "    'job_start_date',\n",
    "    'dobrundate'\n",
    "]\n",
    "\n",
    "perm_dob_description = 'DOB Permits'\n",
    "perm_dob_input_csv_file = BASE_DIR+'DOB/Data Files/IssuedPermits/DOB_Permit_Issuance.csv'  \n",
    "perm_dob_output_pickle = BASE_DIR+'DOB/Data Files/IssuedPermits/df_dob_permit.pkl' \n",
    "perm_dob_input_pickle = BASE_DIR+'DOB/Data Files/IssuedPermits/df_dob_permit.pkl' \n",
    "perm_dob_sep_char = \",\"\n",
    "perm_dob_table_name = \"dob_permits\"\n",
    "perm_dob_load_pickle = True\n",
    "perm_dob_db_action = \"replace\"\n",
    "perm_dob_truncate_columns = ['borough']\n",
    "perm_dob_chunk_size = 2500\n",
    "\n",
    "hpd_csv2sql(\n",
    "            perm_dob_description,\n",
    "            perm_dob_input_csv_file, \n",
    "            perm_dob_sep_char,\n",
    "            perm_dob_output_pickle, \n",
    "            perm_dob_table_name, \n",
    "            perm_dob_dtype_dict, \n",
    "            perm_dob_load_pickle,   \n",
    "            perm_dob_input_pickle,\n",
    "            perm_dob_db_action, \n",
    "            perm_dob_truncate_columns, \n",
    "            perm_dob_date_time_columns, \n",
    "            perm_dob_chunk_size,\n",
    "            perm_dob_df_keep_cols\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPD Violations\n",
    "https://data.cityofnewyork.us/Housing-Development/Housing-Maintenance-Code-Violations/wvxf-dwi5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T23:09:20.773653",
     "start_time": "2016-11-20T22:26:55.239635"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vio_dtype_dict = {\n",
    "'ViolationID':                'int64',\n",
    "'BuildingID':                 'int64',\n",
    "'RegistrationID':             'int64',\n",
    "'BoroID':                     'int64',\n",
    "'Boro':                      'object',\n",
    "'HouseNumber':               'object',\n",
    "'LowHouseNumber':            'object',\n",
    "'HighHouseNumber':           'object',\n",
    "'StreetName':                'object',\n",
    "'StreetCode':                 'int64',\n",
    "'Zip':                      'float64',\n",
    "'Apartment':                 'object',\n",
    "'Story':                     'object',\n",
    "'Block':                      'int64',\n",
    "'Lot':                        'int64',\n",
    "'Class':                     'object',\n",
    "'InspectionDate':            'object',\n",
    "'ApprovedDate':              'object',\n",
    "'OriginalCertifyByDate':     'object',\n",
    "'OriginalCorrectByDate':     'object',\n",
    "'NewCertifyByDate':          'object',\n",
    "'NewCorrectByDate':          'object',\n",
    "'CertifiedDate':             'object',\n",
    "'OrderNumber':               'object',\n",
    "'NOVID':                    'float64',\n",
    "'NOVDescription':            'object',\n",
    "'NOVIssuedDate':             'object',\n",
    "'CurrentStatusID':            'int64',\n",
    "'CurrentStatus':             'object',\n",
    "'CurrentStatusDate':         'object'\n",
    "}    \n",
    "\n",
    "\n",
    "\n",
    "vio_date_time_columns = ['inspectiondate',\n",
    "'approveddate',\n",
    "'originalcertifybydate',\n",
    "'originalcorrectbydate',\n",
    "'newcertifybydate',\n",
    "'newcorrectbydate',\n",
    "'certifieddate',\n",
    "'novissueddate',\n",
    "'currentstatusdate'] \n",
    "    \n",
    "vio_df_keep_cols = [\n",
    "    'violationid',\n",
    "    'buildingid',\n",
    "    'registrationid',\n",
    "    'boroid',\n",
    "    'boro',\n",
    "    'housenumber',\n",
    "    'lowhousenumber',\n",
    "    'highhousenumber',\n",
    "    'streetname',\n",
    "    'streetcode',\n",
    "    'zip',\n",
    "    'apartment',\n",
    "    'story',\n",
    "    'block',\n",
    "    'lot',\n",
    "    'class',\n",
    "    'inspectiondate',\n",
    "    'approveddate',\n",
    "    'originalcertifybydate',\n",
    "    'originalcorrectbydate',\n",
    "    'newcertifybydate',\n",
    "    'newcorrectbydate',\n",
    "    'certifieddate',\n",
    "    'ordernumber',\n",
    "    'novid',\n",
    "    'novdescription',\n",
    "    'novissueddate',\n",
    "    'currentstatusid',\n",
    "    'currentstatus',\n",
    "    'currentstatusdate'\n",
    "]\n",
    "vio_description = \"HPD Violations\"\n",
    "vio_input_csv_file = BASE_DIR+'HPD/Data Files/Violations/Housing_Maintenance_Code_Violations.csv'\n",
    "vio_sep_char = \",\"\n",
    "vio_output_pickle = BASE_DIR+'HPD/Data Files/Violations/df_violations.pkl'\n",
    "vio_table_name = 'hpd_violations'\n",
    "vio_load_pickle = True\n",
    "vio_input_pickle = BASE_DIR+'HPD/Data Files/Violations/df_violations.pkl'\n",
    "vio_db_action = 'replace' ## if not = 'replace' then 'append' \n",
    "vio_truncate_columns = ['novdescription']\n",
    "vio_chunk_size = 5000\n",
    "\n",
    "hpd_csv2sql(\n",
    "            vio_description,\n",
    "            vio_input_csv_file, \n",
    "            vio_sep_char,\n",
    "            vio_output_pickle, \n",
    "            vio_table_name, \n",
    "            vio_dtype_dict, \n",
    "            vio_load_pickle,     # ATTEMPT TO LOAD PICKLE FILE (specfified above as 'input_pickle')\n",
    "            vio_input_pickle,\n",
    "            vio_db_action, # DB ACTiON set as REPLACE (rather than APPEND)\n",
    "            vio_truncate_columns, \n",
    "            vio_date_time_columns, \n",
    "            vio_chunk_size,\n",
    "            vio_df_keep_cols\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPD Buildings \n",
    "https://data.cityofnewyork.us/Housing-Development/Buildings-Subject-to-HPD-Jurisdiction/kj4p-ruqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T23:16:11.590250",
     "start_time": "2016-11-20T23:09:20.777146"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bld_dtype_dict = {\n",
    "'BuildingID':              'int64',\n",
    "'BoroID':                  'int64',\n",
    "'Boro':                   'object',\n",
    "'HouseNumber':            'object',\n",
    "'LowHouseNumber':         'object',\n",
    "'HighHouseNumber':        'object',\n",
    "'StreetName':             'object',\n",
    "'Zip':                    'object',\n",
    "'Block':                   'int64',\n",
    "'Lot':                     'int64',\n",
    "'BIN':                   'float64',\n",
    "'CommunityBoard':          'int64',\n",
    "'CensusTract':           'float64',\n",
    "'ManagementProgram':      'object',\n",
    "'DoBBuildingClassID':    'float64',\n",
    "'DoBBuildingClass':       'object',\n",
    "'LegalStories':          'float64',\n",
    "'LegalClassA':           'float64',\n",
    "'LegalClassB':           'float64',\n",
    "'RegistrationID':          'int64',\n",
    "'LifeCycle':              'object',\n",
    "'RecordStatusID':          'int64',\n",
    "'RecordStatus':           'object'\n",
    "}\n",
    "\n",
    "bld_df_keep_cols = [\n",
    "    'buildingid',\n",
    "    'boroid',\n",
    "    'boro',\n",
    "    'housenumber',\n",
    "    'lowhousenumber',\n",
    "    'highhousenumber',\n",
    "    'streetname',\n",
    "    'zip',\n",
    "    'block',\n",
    "    'lot',\n",
    "    'bin',\n",
    "    'communityboard',\n",
    "    'censustract',\n",
    "    'managementprogram',\n",
    "    'dobbuildingclassid',\n",
    "    'dobbuildingclass',\n",
    "    'legalstories',\n",
    "    'legalclassa',\n",
    "    'legalclassb',\n",
    "    'registrationid',\n",
    "    'lifecycle',\n",
    "    'recordstatusid',\n",
    "    'recordstatus'\n",
    "]\n",
    "\n",
    "bld_description = \"HPD Buildings\"\n",
    "bld_input_csv_file = BASE_DIR+'HPD/Data Files/Buildings/Buildings_Subject_to_HPD_Jurisdiction.csv'\n",
    "bld_sep_char = \",\"\n",
    "bld_output_pickle = BASE_DIR+'HPD/Data Files/Buildings/df_buildings.pkl'\n",
    "bld_table_name = 'hpd_buildings'\n",
    "bld_load_pickle = True\n",
    "bld_input_pickle = BASE_DIR+'HPD/Data Files/Buildings/df_buildings.pkl'\n",
    "bld_db_action = 'replace' ## if not = 'replace' then 'append' \n",
    "bld_truncate_columns = ''\n",
    "bld_date_time_columns = ''\n",
    "bld_chunk_size = 5000\n",
    "\n",
    "\n",
    "hpd_csv2sql(\n",
    "            bld_description,\n",
    "            bld_input_csv_file, \n",
    "            bld_sep_char,\n",
    "            bld_output_pickle, \n",
    "            bld_table_name, \n",
    "            bld_dtype_dict, \n",
    "            bld_load_pickle,    \n",
    "            bld_input_pickle,\n",
    "            bld_db_action, \n",
    "            bld_truncate_columns, \n",
    "            bld_date_time_columns, \n",
    "            bld_chunk_size,\n",
    "            bld_df_keep_cols\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPD Complaints\n",
    "https://data.cityofnewyork.us/Housing-Development/Housing-Maintenance-Code-Complaints/uwyv-629c\n",
    "\n",
    "Please note: the `ReferenceNumber` that is described in the Data Doc for HPD Complaints doesn't actually exist in the data. I have checked the .csv files and the .xml files and the Socrata .. which is too bad because that was described as the \"Complaint link\" back to 311. Here is the snip from the data doc: \n",
    "   `ReferenceNumber - string`\n",
    "Contains the unique identifier of the complaint\n",
    "record from external sources. If complaint is\n",
    "made through 311, the field will contain the\n",
    "service request number. If problem is found\n",
    "during an inspection, the field will contain the\n",
    "ComplaintID, if found during reinspection, the\n",
    "field will contain InspectionID (edited)\n",
    "  \n",
    "This means that we can link the 311 to complaints or violations by street address, but not by actual complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T23:26:02.662695",
     "start_time": "2016-11-20T23:16:11.593030"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmp_dtype_dict = {\n",
    "'ComplaintID':         'int64',\n",
    "'BuildingID':          'int64',\n",
    "'BoroughID':           'int64',\n",
    "'Borough':            'object',\n",
    "'HouseNumber':        'object',\n",
    "'StreetName':         'object',\n",
    "'Zip':               'float64',\n",
    "'Block':               'int64',\n",
    "'Lot':                 'int64',\n",
    "'Apartment':          'object',\n",
    "'CommunityBoard':      'int64',\n",
    "'ReceivedDate':       'object',\n",
    "'StatusID':            'int64',\n",
    "'Status':             'object',\n",
    "'StatusDate':         'object'\n",
    "}\n",
    "\n",
    "cmp_df_keep_cols = [\n",
    "    'complaintid',\n",
    "    'buildingid',\n",
    "    'boroughid',\n",
    "    'borough',\n",
    "    'housenumber',\n",
    "    'streetname',\n",
    "    'zip',\n",
    "    'block',\n",
    "    'lot',\n",
    "    'apartment',\n",
    "    'communityboard',\n",
    "    'receiveddate',\n",
    "    'statusid',\n",
    "    'status',\n",
    "    'statusdate'\n",
    "]\n",
    "\n",
    "cmp_date_time_columns = ['statusdate','receiveddate']\n",
    "\n",
    "cmp_truncate_columns = ''\n",
    "\n",
    "cmp_description = \"HPD Complaints\"\n",
    "cmp_input_csv_file = BASE_DIR+'HPD/Data Files/Complaints/Housing_Maintenance_Code_Complaints.csv'\n",
    "cmp_sep_char = \",\"\n",
    "cmp_output_pickle = BASE_DIR+'HPD/Data Files/Complaints/df_complaints.pkl'\n",
    "cmp_table_name = 'hpd_complaints'\n",
    "cmp_load_pickle = True\n",
    "cmp_input_pickle = BASE_DIR+'HPD/Data Files/Complaints/df_complaints.pkl'\n",
    "cmp_db_action = 'replace' ## if not = 'replace' then 'append' \n",
    "cmp_chunk_size = 5000\n",
    "\n",
    "hpd_csv2sql(\n",
    "            cmp_description,\n",
    "            cmp_input_csv_file, \n",
    "            cmp_sep_char,\n",
    "            cmp_output_pickle, \n",
    "            cmp_table_name, \n",
    "            cmp_dtype_dict, \n",
    "            cmp_load_pickle,   \n",
    "            cmp_input_pickle,\n",
    "            cmp_db_action,\n",
    "            cmp_truncate_columns, \n",
    "            cmp_date_time_columns, \n",
    "            cmp_chunk_size,\n",
    "            cmp_df_keep_cols\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPD Complaint - Problems\n",
    "https://data.cityofnewyork.us/Housing-Development/Complaint-Problems/a2nx-4u46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:06:41.126157",
     "start_time": "2016-11-21T00:43:42.725072"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'CLOSE'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'BATHTUB/SHOWER'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'BATHROOM'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'PLUMBING'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'APARTMENT'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value ' The Department of Housin...'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'BROKEN OR MISSING'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'CHIPPED OR RUSTED'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'BEDROOM'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n",
      "/Applications/anaconda/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:219: SAWarning: Unicode type received non-unicode bind param value 'APARTMENT ONLY'. (this warning may be suppressed after 10 occurrences)\n",
      "  (util.ellipses_string(value),))\n"
     ]
    }
   ],
   "source": [
    "cpb_dtype_dict = {\n",
    "'ProblemID':             'int64',\n",
    "'ComplaintID':           'int64',\n",
    "'UnitTypeID':            'int64',\n",
    "'UnitType':             'object',\n",
    "'SpaceTypeID':           'int64',\n",
    "'SpaceType':            'object',\n",
    "'TypeID':                'int64',\n",
    "'Type':                 'object',\n",
    "'MajorCategoryID':       'int64',\n",
    "'MajorCategory':        'object',\n",
    "'MinorCategoryID':       'int64',\n",
    "'MinorCategory':        'object',\n",
    "'CodeID':                'int64',\n",
    "'Code':                 'object',\n",
    "'StatusID':              'int64',\n",
    "'Status':               'object',\n",
    "'StatusDate':           'object',\n",
    "'StatusDescription':    'object',\n",
    "}\n",
    "\n",
    "cpb_date_time_columns = ['statusdate']\n",
    "\n",
    "cpb_df_keep_cols = [\n",
    "    'problemid',\n",
    "    'complaintid',\n",
    "    'unittypeid',\n",
    "    'unittype',\n",
    "    'spacetypeid',\n",
    "    'spacetype',\n",
    "    'typeid',\n",
    "    'type',\n",
    "    'majorcategoryid',\n",
    "    'majorcategory',\n",
    "    'minorcategoryid',\n",
    "    'minorcategory',\n",
    "    'codeid',\n",
    "    'code',\n",
    "    'statusid',\n",
    "    'status',\n",
    "    'statusdate',\n",
    "    'statusdescription'\n",
    "]\n",
    "\n",
    "\n",
    "cpb_description = \"HPD ComplaintProblems\"\n",
    "cpb_input_csv_file = BASE_DIR+'HPD/Data Files/Complaints/Complaint_Problems.csv'\n",
    "cpb_sep_char = \",\"\n",
    "cpb_output_pickle = BASE_DIR+'HPD/Data Files/Complaints/df_prob.pkl'\n",
    "cpb_table_name = 'hpd_complaintsProb'\n",
    "cpb_load_pickle = True\n",
    "cpb_input_pickle = BASE_DIR+'HPD/Data Files/Complaints/df_prob.pkl'\n",
    "cpb_db_action = 'replace'\n",
    "cpb_chunk_size = 5000\n",
    "cpb_truncate_columns = ['statusdescription']\n",
    "\n",
    "hpd_csv2sql(\n",
    "            cpb_description,\n",
    "            cpb_input_csv_file, \n",
    "            cpb_sep_char,\n",
    "            cpb_output_pickle, \n",
    "            cpb_table_name, \n",
    "            cpb_dtype_dict, \n",
    "            cpb_load_pickle,\n",
    "            cpb_input_pickle,\n",
    "            cpb_db_action,\n",
    "            cpb_truncate_columns, \n",
    "            cpb_date_time_columns, \n",
    "            cpb_chunk_size,\n",
    "            cpb_df_keep_cols\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registrations\n",
    "https://data.cityofnewyork.us/Housing-Development/Multiple-Dwelling-Registrations/tesw-yqqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T23:54:25.245007",
     "start_time": "2016-11-20T23:51:37.314435"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_dtype_dict = {\n",
    "'RegistrationID':            'int64',\n",
    "'BuildingID':                'int64',\n",
    "'BoroID':                    'int64',\n",
    "'Boro':                     'object',\n",
    "'HouseNumber':              'object',\n",
    "'LowHouseNumber':           'object',\n",
    "'HighHouseNumber':          'object',\n",
    "'StreetName':               'object',\n",
    "'StreetCode':               'int64',\n",
    "'Zip':                     'float64',\n",
    "'Block':                     'int64',\n",
    "'Lot':                       'int64',\n",
    "'BIN':                     'float64',\n",
    "'CommunityBoard':            'int64',\n",
    "'LastRegistrationDate':     'object',\n",
    "'RegistrationEndDate':      'object'}\n",
    "\n",
    "reg_df_keep_cols = [\n",
    "    'registrationid',\n",
    "    'buildingid',\n",
    "    'boroid',\n",
    "    'boro',\n",
    "    'housenumber',\n",
    "    'lowhousenumber',\n",
    "    'highhousenumber',\n",
    "    'streetname',\n",
    "    'streetcode',\n",
    "    'zip',\n",
    "    'block',\n",
    "    'lot',\n",
    "    'bin',\n",
    "    'communityboard',\n",
    "    'lastregistrationdate',\n",
    "    'registrationenddate'\n",
    "]\n",
    "\n",
    "reg_date_time_columns = ['lastregistrationdate', 'registrationenddate']\n",
    "reg_truncate_columns = ''\n",
    "\n",
    "reg_description = \"HPD Registrations\"\n",
    "reg_input_csv_file = BASE_DIR+'HPD/Data Files/Registrations/Multiple_Dwelling_Registrations.csv'\n",
    "reg_sep_char = \",\"\n",
    "reg_output_pickle = BASE_DIR+'HPD/Data Files/Registrations/df_reg.pkl'\n",
    "reg_table_name = 'hpd_registrations'\n",
    "reg_load_pickle = True\n",
    "reg_input_pickle = BASE_DIR+'HPD/Data Files/Registrations/df_reg.pkl'\n",
    "reg_db_action = 'replace' ## if not = 'replace' then 'append' \n",
    "reg_chunk_size = 5000\n",
    "\n",
    "hpd_csv2sql(\n",
    "            reg_description,\n",
    "            reg_input_csv_file, \n",
    "            reg_sep_char,\n",
    "            reg_output_pickle, \n",
    "            reg_table_name, \n",
    "            reg_dtype_dict, \n",
    "            reg_load_pickle,   \n",
    "            reg_input_pickle,\n",
    "            reg_db_action, \n",
    "            reg_truncate_columns, \n",
    "            reg_date_time_columns, \n",
    "            reg_chunk_size,\n",
    "            reg_df_keep_cols\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration Contacts\n",
    "https://data.cityofnewyork.us/Housing-Development/Registration-Contacts/feu5-w2e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T00:04:13.214479",
     "start_time": "2016-11-20T23:54:25.249247"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcn_dtype_dict = {\n",
    "'RegistrationContactID':     'int64',\n",
    "'RegistrationID':            'int64',\n",
    "'Type':                     'object',\n",
    "'ContactDescription':       'object',\n",
    "'CorporationName':          'object',\n",
    "'Title':                    'object',\n",
    "'FirstName':                'object',\n",
    "'MiddleInitial':            'object',\n",
    "'LastName':                 'object',\n",
    "'BusinessHouseNumber':      'object',\n",
    "'BusinessStreetName':       'object',\n",
    "'BusinessApartment':        'object',\n",
    "'BusinessCity':             'object',\n",
    "'BusinessState':            'object',\n",
    "'BusinessZip':              'object'\n",
    "    }\n",
    "\n",
    "rcn_df_keep_cols = [\n",
    "    'registrationcontactid',\n",
    "    'registrationid',\n",
    "    'type',\n",
    "    'contactdescription',\n",
    "    'corporationname',\n",
    "    'title',\n",
    "    'firstname',\n",
    "    'middleinitial',\n",
    "    'lastname',\n",
    "    'businesshousenumber',\n",
    "    'businessstreetname',\n",
    "    'businessapartment',\n",
    "    'businesscity',\n",
    "    'businessstate',\n",
    "    'businesszip'\n",
    "]\n",
    "\n",
    "rcn_truncate_columns = ''\n",
    "\n",
    "rcn_date_time_columns = ''\n",
    "\n",
    "rcn_description = \"HPD RegistrationsContacts\"\n",
    "rcn_input_csv_file = BASE_DIR+'HPD/Data Files/Registrations/Registration_Contacts.csv'\n",
    "rcn_sep_char = \",\"\n",
    "rcn_output_pickle = BASE_DIR+'HPD/Data Files/Registrations/df_regCon.pkl'\n",
    "rcn_table_name = 'hpd_registrationContact'\n",
    "rcn_load_pickle = True\n",
    "rcn_input_pickle = BASE_DIR+'HPD/Data Files/Registrations/df_regCon.pkl'\n",
    "rcn_db_action = 'replace' ## if not = 'replace' then 'append' \n",
    "rcn_chunk_size = 5000\n",
    "\n",
    "hpd_csv2sql(\n",
    "            rcn_description,\n",
    "            rcn_input_csv_file, \n",
    "            rcn_sep_char,\n",
    "            rcn_output_pickle, \n",
    "            rcn_table_name, \n",
    "            rcn_dtype_dict, \n",
    "            rcn_load_pickle,\n",
    "            rcn_input_pickle,\n",
    "            rcn_db_action,\n",
    "            rcn_truncate_columns, \n",
    "            rcn_date_time_columns, \n",
    "            rcn_chunk_size,\n",
    "            rcn_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 311 Import\n",
    "https://nycopendata.socrata.com/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:07:26.536909",
     "start_time": "2016-11-21T01:07:26.438386"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call_311_dtype_dict = {'Unique Key':'int64',\n",
    "'Created Date':'object',\n",
    "'Closed Date':'object',\n",
    "'Agency':'object',\n",
    "'Agency Name':'object',\n",
    "'Complaint Type':'object',\n",
    "'Descriptor':'object',\n",
    "'Location Type':'object',\n",
    "'Incident Zip':'object',\n",
    "'Incident Address':'object',\n",
    "'Street Name':'object',\n",
    "'Cross Street 1':'object',\n",
    "'Cross Street 2':'object',\n",
    "'Intersection Street 1':'object',\n",
    "'Intersection Street 2':'object',\n",
    "'Address Type':'object',\n",
    "'City':'object',\n",
    "'Landmark':'object',\n",
    "'Facility Type':'object',\n",
    "'Status':'object',\n",
    "'Due Date':'object',\n",
    "'Resolution Description':'object',\n",
    "'Resolution Action Updated Date':'object',\n",
    "'Community Board':'object',\n",
    "'Borough':'object',\n",
    "'X Coordinate (State Plane)':'float64',\n",
    "'Y Coordinate (State Plane)':'float64',\n",
    "'Park Facility Name':'object',\n",
    "'Park Borough':'object',\n",
    "'School Name':'object',\n",
    "'School Number':'object',\n",
    "'School Region':'object',\n",
    "'School Code':'object',\n",
    "'School Phone Number':'object',\n",
    "'School Address':'object',\n",
    "'School City':'object',\n",
    "'School State':'object',\n",
    "'School Zip':'object',\n",
    "'School Not Found':'object',\n",
    "'School or Citywide Complaint':'float64',\n",
    "'Vehicle Type':'object',\n",
    "'Taxi Company Borough':'object',\n",
    "'Taxi Pick Up Location':'object',\n",
    "'Bridge Highway Name':'object',\n",
    "'Bridge Highway Direction':'object',\n",
    "'Road Ramp':'object',\n",
    "'Bridge Highway Segment':'object',\n",
    "'Garage Lot Name':'object',\n",
    "'Ferry Direction':'object',\n",
    "'Ferry Terminal Name':'object',\n",
    "'Latitude':'float64',\n",
    "'Longitude':'float64',\n",
    "'Location':'object'}\n",
    "\n",
    "call_311_df_keep_cols = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"closed_date\",\n",
    "    \"agency\",\n",
    "    \"complaint_type\",\n",
    "    \"descriptor\",\n",
    "    \"incident_zip\",\n",
    "    \"incident_address\",\n",
    "    \"street_name\",\n",
    "    \"cross_street_1\",\n",
    "    \"cross_street_2\",\n",
    "    \"intersection_street_1\",\n",
    "    \"intersection_street_2\",\n",
    "    \"city\",\n",
    "    \"status\",\n",
    "    \"due_date\",\n",
    "    \"resolution_description\",\n",
    "    \"resolution_action_updated_date\",\n",
    "    \"borough\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"location\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: each \"split\" of 250K rows takes about 15min on a macbook air laptop over wifi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:14:56.622319",
     "start_time": "2016-11-21T01:07:26.540669"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xaa\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xaa_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xaa_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xaa_c'\n",
    "call_311_sep_char = \",\"\n",
    "call_311_table_name = \"call_311\"\n",
    "call_311_load_pickle = True\n",
    "call_311_db_action = 'replace' ## if not = 'replace' then 'append' \n",
    "call_311_truncate_columns = ['resolution_description']\n",
    "call_311_date_time_columns = ['created_date','closed_date','due_date', 'resolution_action_updated_date']\n",
    "call_311_chunk_size = 2500\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:22:26.070879",
     "start_time": "2016-11-21T01:14:56.625447"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xab\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xab_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xab_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xab_c'\n",
    "call_311_db_action = 'append' ## if not = 'replace' then 'append' \n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:30:16.867468",
     "start_time": "2016-11-21T01:22:26.075173"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xac\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xac_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xac_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xac_c'\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:37:50.924962",
     "start_time": "2016-11-21T01:30:16.870322"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xad\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xad_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xad_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xad_c'\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:45:59.329333",
     "start_time": "2016-11-21T01:37:50.928155"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xae\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xae_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xae_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xae_c'\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T01:55:00.541288",
     "start_time": "2016-11-21T01:45:59.332371"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xaf\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xaf_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xaf_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xaf_c'\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T02:03:55.908437",
     "start_time": "2016-11-21T01:55:00.546758"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xag\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xag_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xag_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xag_c'\n",
    "\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T02:13:49.343130",
     "start_time": "2016-11-21T02:03:55.912604"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xah\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xah_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xah_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xah_c'\n",
    "\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-21T02:16:35.824007",
     "start_time": "2016-11-21T02:13:49.353882"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_311_description = \"311_xai\"\n",
    "call_311_input_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xai_c.pkl'\n",
    "call_311_output_pickle = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xai_c.pkl'\n",
    "call_311_input_csv_file = BASE_DIR + '311/Data Files/2016_Jan1-Nov14/xai_c'\n",
    "\n",
    "\n",
    "hpd_csv2sql(\n",
    "            call_311_description,\n",
    "            call_311_input_csv_file, \n",
    "            call_311_sep_char,\n",
    "            call_311_output_pickle, \n",
    "            call_311_table_name, \n",
    "            call_311_dtype_dict, \n",
    "            call_311_load_pickle,   \n",
    "            call_311_input_pickle,\n",
    "            call_311_db_action,\n",
    "            call_311_truncate_columns, \n",
    "            call_311_date_time_columns, \n",
    "            call_311_chunk_size,\n",
    "            call_311_df_keep_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc SQL queries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-16T22:57:43.075424",
     "start_time": "2016-11-16T22:57:43.049995"
    },
    "collapsed": true
   },
   "source": [
    "# Large 311 Select with ages\n",
    "#\n",
    "# SELECT \n",
    "# `Unique Key`,\n",
    "# `Created Date`, \n",
    "# `Closed Date`,\n",
    "# timestampdiff(day,`Created Date`,`Closed Date`) as AgeDays,\n",
    "# timestampdiff(hour,`Created Date`,`Closed Date`) as AgeHr,\n",
    "# `Agency`,\n",
    "#  `Complaint Type`\n",
    "# ,`Descriptor`,\n",
    "# `Location Type`,\n",
    "#  `Incident Zip`, \n",
    "# `Incident Address`,\n",
    "# `Facility Type`,\n",
    "#  `Status`,\n",
    "# `Due Date`,\n",
    "# `Borough`,\n",
    "#  `Resolution Description`,\n",
    "# `Resolution Action Updated Date`,\n",
    "# `Latitude`,\n",
    "#  `Longitude` \n",
    "# FROM `call_311` \n",
    "# WHERE Agency = \"HPD\" and `Complaint Type` = \"HEAT/HOT WATER\" and `Status` != \"Closed\"\n",
    "\n",
    "\n",
    "\n",
    "# COUNT OF HEAT/HW with locations\n",
    "#\n",
    "# SELECT * \n",
    "# FROM (\n",
    "# SELECT  `Incident Address` ,  `Borough` ,  `Latitude` ,  `Longitude` , COUNT(  `Unique Key` ) AS count, AVG( timestampdiff(\n",
    "# DAY ,  `Created Date` ,  `Closed Date`\n",
    "# ) ) AS average_day_age\n",
    "# FROM call_311\n",
    "# WHERE Agency =  \"HPD\"\n",
    "# AND  `Complaint Type` =  \"HEAT/HOT WATER\"\n",
    "# AND  `Status` =  'Closed'\n",
    "# GROUP BY  `Incident Address`\n",
    "# ) AS count_table\n",
    "# ORDER BY average_day_age DESC\n",
    "\n",
    "\n",
    "#\n",
    "#SELECT TABLE_ROWS, TABLE NAME\n",
    "#      FROM INFORMATION_SCHEMA.TABLES \n",
    "#      WHERE TABLE_SCHEMA = 'heatseak' AND\n",
    "#         TABLE_NAME NOT LIKE '%pma_%';\n",
    "\n",
    "## LIST ALL COLUMNS OF ALL TABLES WITH COL TYPE\n",
    "select table_name, column_name, data_type \n",
    "from information_schema.columns where table_schema = 'heatseek' \n",
    "order by table_name,ordinal_position;\n",
    "\n",
    "## LIST COUNT OF VIOLATION STATUS AND CLASS HPD VIOLATIONS\n",
    "select class, currentstatus, count(violationid) as \n",
    "count from hpd_violations group by currentstatus, class;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table indexes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T22:15:03.194595",
     "start_time": "2016-11-20T22:15:03.145711"
    },
    "collapsed": true
   },
   "source": [
    "# hpd_buildings indexes\n",
    "ALTER TABLE `hpd_buildings` ADD PRIMARY KEY(`BuildingID`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`BoroID`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`RecordStatus`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`BIN`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`Lot`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`Block`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`StreetName`);\n",
    "ALTER TABLE `hpd_buildings` ADD INDEX(`HouseNumber`);\n",
    "\n",
    "## hpd_complaints indexes\n",
    "ALTER TABLE `hpd_complaints` ADD PRIMARY KEY(`ComplaintID`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`StatusDate`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`Status`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`Lot`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`Block`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`StreetName`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`HouseNumber`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`BoroughID`);\n",
    "ALTER TABLE `hpd_complaints` ADD INDEX(`BuildingID`);\n",
    "\n",
    "## hpd_complaint_problem indexes\n",
    "ALTER TABLE `hpd_complaint_problem` ADD PRIMARY KEY(`ProblemID`);\n",
    "ALTER TABLE `hpd_complaint_problem` ADD INDEX(`ComplaintID`);\n",
    "ALTER TABLE `hpd_complaint_problem` ADD INDEX(`MajorCategory`);\n",
    "ALTER TABLE `hpd_complaint_problem` ADD INDEX(`MinorCategory`);\n",
    "ALTER TABLE `hpd_complaint_problem` ADD INDEX(`Status`);\n",
    "ALTER TABLE `hpd_complaint_problem` ADD INDEX(`StatusDate`);\n",
    "\n",
    "## hpd_registration indexes\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`RegistrationID`); #1062 - Duplicate entry '913236' for key 'PRIMARY'\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`BuildingID`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`BoroID`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`HouseNumber`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`StreetName`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`Block`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`Lot`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`BIN`);\n",
    "ALTER TABLE `hpd_registration` ADD INDEX(`RegistrationEndDate`);\n",
    "\n",
    "## hpd_registrationContact indexes\n",
    "ALTER TABLE `hpd_registrationContact` ADD INDEX(`RegistrationContactID`); ##1062 - Duplicate entry '91323603' for key 'PRIMARY'\n",
    "ALTER TABLE `hpd_registrationContact` ADD INDEX(`RegistrationID`);\n",
    "\n",
    "## call_311 indexes\n",
    "ALTER TABLE `call_311` ADD PRIMARY KEY(`Unique Key`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Created Date`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Agency`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Complaint Type`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Descriptor`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Incident Address`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Status`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Latitude`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Longitude`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Resolution Description`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Resolution Action Updated Date`);\n",
    "ALTER TABLE `call_311` ADD INDEX(`Borough`);\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "564px",
   "left": "0px",
   "right": "1133px",
   "top": "130px",
   "width": "238px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
